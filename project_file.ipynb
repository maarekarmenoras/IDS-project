{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e65d48e5",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn.utils'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m preprocessing\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtime\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\__init__.py:83\u001b[0m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# We are not importing the rest of scikit-learn during the build\u001b[39;00m\n\u001b[0;32m     70\u001b[0m     \u001b[38;5;66;03m# process, as it may not be compiled yet\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     77\u001b[0m     \u001b[38;5;66;03m# later is linked to the OpenMP runtime to make it possible to introspect\u001b[39;00m\n\u001b[0;32m     78\u001b[0m     \u001b[38;5;66;03m# it and importing it first would fail if the OpenMP dll cannot be found.\u001b[39;00m\n\u001b[0;32m     79\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     80\u001b[0m         __check_build,  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[0;32m     81\u001b[0m         _distributor_init,  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[0;32m     82\u001b[0m     )\n\u001b[1;32m---> 83\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m clone\n\u001b[0;32m     84\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_show_versions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m show_versions\n\u001b[0;32m     86\u001b[0m     __all__ \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     87\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcalibration\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     88\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcluster\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    129\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshow_versions\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    130\u001b[0m     ]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:19\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_config\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m config_context, get_config\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexceptions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m InconsistentVersionWarning\n\u001b[1;32m---> 19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _IS_32BIT\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_estimator_html_repr\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m estimator_html_repr\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_metadata_requests\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _MetadataRequester\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'sklearn.utils'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "%pip install --upgrade scikit-learn\n",
    "%pip install --upgrade imbalanced-learn\n",
    "\n",
    "from imblearn.over_sampling import RandomOverSampler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b95116f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('data/fraudTrain.csv')\n",
    "test_data = pd.read_csv('data/fraudTest.csv')\n",
    "\n",
    "train_data['is_train'] = 1\n",
    "test_data['is_train'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b4c95b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "split = train_data.size\n",
    "data = pd.concat([train_data, test_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcb6d8fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.tail()\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "210e3a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_labels(df, column_name):\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    data[column_name] = le.fit_transform(df[column_name])\n",
    "    return data\n",
    "\n",
    "def encode_onehot(df, column_name):\n",
    "    return pd.get_dummies(df, columns=[column_name])\n",
    "\n",
    "def minmax_scale(df, column_name):\n",
    "    scaler = preprocessing.MinMacScaler()\n",
    "    data = scaler.fit_transform(df[column_name])\n",
    "    return scaler, data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e2b2e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_epoch(df, column_name):\n",
    "    for name, value in df[column_name].iteritems():\n",
    "        value = time.strptime(value)\n",
    "    return df[column_name]\n",
    "    \n",
    "def convert_utc(df, column_name):\n",
    "    for name, value in df[column_name].iteritems():\n",
    "        value = time.gmtime(value)\n",
    "    return df[column_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de2c3e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def oversampling(df, column_name):\n",
    "    oversampler = RandomOverSampler(sampling_strategy='auto', random_state=0)\n",
    "    X = df.drop(column_name, axis=1)\n",
    "    y = df[column_name]\n",
    "    X_resampled, y_resampled = oversampler.fit_resample(X, y)\n",
    "    resampled_df = pd.concat([pd.DataFrame(X_resampled, columns=X.columns), pd.Series(y_resampled, name=column_name)], axis=1)\n",
    "    return resampled_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5091b1ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateAgeWithDateOfBirth(df,column_name):\n",
    "    from datetime import datetime\n",
    "    df[column_name]= pd.to_datetime(data[column_name])\n",
    "    current_date= datetime.now()\n",
    "    \n",
    "    df['age_in_years']= (current_date-data[column_name]).astype('<m8[Y]')\n",
    "    df['age_in_years'] = df['age_in_years'].map(lambda x: int(x))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00da0ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeGenderBinary(df, gender_column):\n",
    "    df[gender_column]=df[gender_column].map(lambda x: 1 if x == 'M' else 0)\n",
    "    return df\n",
    "\n",
    "def convert_to_unixtime(df, datetime_column):\n",
    "\n",
    "    df['unix_time'] = pd.to_datetime(df[datetime_column]).astype(int) // 10**9\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de8a9dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitDateAndTime(data,date_and_time_col):\n",
    "    data[date_and_time_col] = pd.to_datetime(data[date_and_time_col])\n",
    "    data['trans_date'] = data[date_and_time_col].dt.strftime('%Y-%m-%d')\n",
    "    data['trans_date'] = pd.to_datetime(data['trans_date'])\n",
    "    data['trans_time'] =data[date_and_time_col].dt.time\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "280a0cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduceDataWithPCA(data, components):\n",
    "    from sklearn.decomposition import PCA\n",
    "    reduced_data = pd.DataFrame(PCA(n_components=components).fit_transform(data))\n",
    "    reduced_data.columns = [\"PC\"+str(i+1) for i in range(components)]\n",
    "    return reduced_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6890387",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d792f4c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## Cleaning the data and feature engineering\n",
    "\n",
    "data = calculateAgeWithDateOfBirth(data,'dob')\n",
    "data = makeGenderBinary(data, 'gender')\n",
    "\n",
    "## if you want to over sample then don't uncomment these lines, the oversampler can not handle so many col\n",
    "#data = encode_onehot(data,'job')\n",
    "#data = encode_onehot(data,'category')\n",
    "#data = splitDateAndTime(data,'trans_date_trans_time')\n",
    "data = data.drop(columns=['Unnamed: 0','first','last','dob','city','street','state','trans_date_trans_time','trans_num','merchant','job','cc_num'])\n",
    "\n",
    "\n",
    "## Splitting the data back to train and test after feature engineering and cleanup\n",
    "train_cleaned = data[data['is_train']==1].drop(columns=['is_train'])\n",
    "test_cleaned = data[data['is_train']==0].drop(columns=['is_train'])\n",
    "\n",
    "print(len(train_cleaned), len(test_cleaned))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3249963e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#add data.to_csv here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba3aee85",
   "metadata": {},
   "outputs": [],
   "source": [
    "## RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "## Oversampling the data\n",
    "oversampled_train = oversampling(train_cleaned,'is_fraud')\n",
    "oversampled_train['is_fraud'].value_counts()\n",
    "oversampled_train = encode_onehot(oversampled_train,'category')\n",
    "\n",
    "oversampled_train_labels = oversampled_train['is_fraud']\n",
    "oversampled_train_data = oversampled_train.drop(columns=['is_fraud'])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(oversampled_train_data,oversampled_train_labels,test_size=0.3,train_size=0.7,random_state=5)\n",
    "\n",
    "rf_1 = RandomForestClassifier(n_estimators=3, max_depth=5, random_state=0).fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c31793",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c2a4153",
   "metadata": {},
   "outputs": [],
   "source": [
    "### ROC curve of rf_1\n",
    "\n",
    "##One hot encoding the test dataset after feature engineering and cleanup\n",
    "test_cleaned_onehot = encode_onehot(test_cleaned,'category')\n",
    "\n",
    "## X and y validation dataframes for predicting probability\n",
    "y_val = test_cleaned_onehot['is_fraud'].squeeze()\n",
    "X_val = test_cleaned_onehot.drop(columns=['is_fraud'])# features\n",
    "probs = rf_1.predict_proba(X_val)\n",
    "\n",
    "probs = pd.DataFrame(probs)# Store in pandas Dataframe with two columns\n",
    "probs = probs[1].squeeze() \n",
    "\n",
    "##finding unique cutoffs\n",
    "cutoffs = pd.DataFrame({'cutoff':probs.unique()})\n",
    "cutoffs = cutoffs.sort_values(by='cutoff',ascending=True)\n",
    "##finding true postive rate and false positive rate\n",
    "tpr = cutoffs.apply(lambda cut: np.sum(np.logical_and(probs >= cut[0], y_val == 1)) / np.sum(y_val == 1), axis=1)\n",
    "fpr = cutoffs.apply(lambda cut: np.sum(np.logical_and(probs >= cut[0], y_val == 0)) / np.sum(y_val == 0), axis=1)\n",
    "\n",
    "stats = pd.DataFrame({'cutoff':cutoffs.cutoff, 'tpr':tpr, 'fpr':fpr})\n",
    "plt.plot(stats['fpr'],stats['tpr'])\n",
    "plt.xlabel('fpr')\n",
    "plt.ylabel('tpr')\n",
    "plt.title('ROC curve for RandomForestClassifier with n_estimators=3 and max_depth=5')\n",
    "plt.show()\n",
    "\n",
    "print(\"Accuracy of rf_1 model on validation data from test_train_split: \",accuracy_score(rf_1.predict(X_test),y_test))\n",
    "print(\"Accuracy of rf_1 model on test data from the separate file: \",accuracy_score(rf_1.predict(X_val),y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a997267",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "y_true = y_val\n",
    "y_pred = rf_1.predict(X_val)\n",
    "print(test_data['is_fraud'].value_counts())\n",
    "print(confusion_matrix(y_true,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad5d25ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "\n",
    "decision_tree = tree.DecisionTreeClassifier()\n",
    "decision_tree.fit(X_train, y_train)\n",
    "tree.plot_tree(decision_tree)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
